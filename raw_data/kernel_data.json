{
  "AI_kernels": {
    "layer_gemm": {
      "time": 0.007852095009984622,
      "flops": 206158430208,
      "tops": 26.255213410669587,
      "bytes_moved": 167772160,
      "efficiency": 1.006770590250207,
      "oom": false,
      "paging": false,
      "fallback_kernel": false
    },
    "attention_output_projection": {
      "time": 0.002692320580017622,
      "flops": 68719476736,
      "tops": 25.52425489224252,
      "bytes_moved": 67108864
    },
    "ffn_gemm": {
      "time": 0.006962994470013655,
      "flops": 184683593728,
      "tops": 26.523587591997302,
      "bytes_moved": 152043520
    },
    "attention_gemm": {
      "time": 0.0023654079300013107,
      "tops": 14.52592507710962,
      "bytes_moved": 603979776,
      "flops": 34359738368
    },
    "softmax": {
      "time": 0.0020706316599989807,
      "bandwidth": 259.2788096364103,
      "flops": 1073741824,
      "tops": 0.5185576192728206,
      "bytes_moved": 536870912
    },
    "attention": {
      "time": 0.004587686730001223,
      "flops": 68719476736,
      "tops": 14.979112738149336,
      "bytes_moved": 67108864,
      "bandwidth": 14.62803978334896
    },
    "layernorm": {
      "time": 0.0001801636999971379,
      "bytes_moved": 33554432,
      "data_throughput": 186.24413242253047,
      "flops": 58720256,
      "tops": 0.3259272317394283
    },
    "activation": {
      "time": 0.0004560966999997618,
      "flops": 125829120,
      "tops": 0.2758825485912652,
      "bytes_moved": 33554432,
      "data_throughput": 73.56867962433739
    }
  }
}